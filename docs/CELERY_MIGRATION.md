# Migration vers Celery pour MonAssurance

## üéØ Objectif

Remplacer le syst√®me de queue RQ actuel par Celery pour une gestion plus robuste des t√¢ches asynchrones, notamment pour la g√©n√©ration de rapports lourds.

## üèóÔ∏è Architecture Celery

### Composants principaux

1. **Celery App** (`backend/app/core/celery_app.py`)
   - Configuration centralis√©e
   - Routing des t√¢ches par queue
   - Gestion des retries et timeouts
   - Beat scheduler pour t√¢ches p√©riodiques

2. **Workers sp√©cialis√©s**
   - **reports**: G√©n√©ration de rapports lourds (2 workers)
   - **documents**: Traitement de documents (1 worker)  
   - **notifications**: Envoi de notifications (1 worker)
   - **celery**: T√¢ches syst√®me g√©n√©rales (1 worker)

3. **Monitoring**
   - **Flower**: Interface web sur port 5555
   - **M√©triques Prometheus**: Int√©gr√©es dans les t√¢ches
   - **Health checks**: Surveillance automatique

## üîÑ Migration RQ ‚Üí Celery

### Changements principaux

1. **Nouveau syst√®me de t√¢ches**
   ```python
   # Ancien (RQ)
   @task
   def generate_dummy_report(report_id: str):
       return {"report_id": report_id}
   
   # Nouveau (Celery)
   @celery_app.task(bind=True, queue="reports", max_retries=3)
   def generate_dummy_report(self, report_id: str, job_id: int = None):
       # Gestion avanc√©e des erreurs et retry
       # M√©triques Prometheus
       # Mise √† jour statut en base
   ```

2. **API routes hybrides**
   - D√©tection automatique Celery/RQ
   - Fallback gracieux vers RQ si Celery indisponible
   - Nouvelles routes pour rapports lourds

3. **Types de rapports support√©s**
   - **dummy**: Rapport factice (existant)
   - **heavy**: Nouveaux rapports lourds (PDF, Excel, Analysis)

## üöÄ D√©ploiement

### Docker Compose

```bash
# D√©marrage avec Celery
docker-compose -f docker-compose.celery.yml up -d

# Services d√©marr√©s:
# - backend (API FastAPI)
# - celery-worker-reports (2 workers pour rapports)
# - celery-worker-documents (1 worker pour documents)
# - celery-worker-general (1 worker g√©n√©ral)
# - celery-beat (scheduler)
# - celery-flower (monitoring web)
# - db (PostgreSQL)
# - redis (broker)
```

### Commandes de gestion

```bash
# Via le script manager
python celery_manager.py worker reports 4    # 4 workers pour rapports
python celery_manager.py beat                # Scheduler
python celery_manager.py flower 5555         # Interface web
python celery_manager.py status              # Statut workers

# Via manage.py
python manage.py celery-worker reports 2
python manage.py celery-beat
python manage.py celery-flower
python manage.py celery-status
```

## üìä Nouvelles fonctionnalit√©s

### 1. Rapports lourds

```bash
# API pour rapports lourds
POST /api/v1/reports/heavy?report_type=pdf&pages=50&processing_time=30

# Types support√©s:
# - pdf: Rapport PDF avec pagination
# - excel: Rapport Excel multi-feuilles  
# - analysis: Rapport d'analyse avec graphiques
```

### 2. Gestion avanc√©e des jobs

```bash
# Annulation de jobs
DELETE /api/v1/reports/jobs/{job_id}

# Listage avec filtres
GET /api/v1/reports/jobs?status=completed&limit=20

# Statut des queues
GET /api/v1/reports/queues/status
```

### 3. Monitoring Flower

Interface web disponible sur `http://localhost:5555`:
- Vue en temps r√©el des workers
- Statut des t√¢ches en cours
- Historique et statistiques
- Graphiques de performance

## üîß Configuration

### Variables d'environnement

```bash
# Redis (broker et backend)
REDIS_URL=redis://localhost:6379/0

# Base de donn√©es pour persistance jobs
DATABASE_URL=postgresql://user:pass@localhost/monassurance

# Environnement (affecte config Celery)
ENVIRONMENT=development|test|production
```

### Queues et priorit√©s

| Queue | Priorit√© | Concurrency | Usage |
|-------|----------|-------------|--------|
| reports | 5 | 2 | Rapports lourds |
| documents | 7 | 1 | Traitement docs |
| notifications | 3 | 1 | Notifications |
| celery | 6 | 1 | T√¢ches syst√®me |

## üìà M√©triques et monitoring

### M√©triques Prometheus

```python
# Nouvelles m√©triques Celery
report_jobs_total{job_type, status, queue}          # Compteur total
report_jobs_duration_seconds{job_type, queue}       # Histogramme dur√©es
report_jobs_active{job_type, queue}                 # Gauge jobs actifs
report_jobs_retries_total{job_type, queue}          # Compteur retries
```

### T√¢ches p√©riodiques (Beat)

- **Nettoyage jobs**: Supprime jobs > 7 jours (chaque heure)
- **Health check**: V√©rification syst√®me (toutes les 5 min)
- **M√©triques quotidiennes**: Rapport journalier (√† minuit)

## üß™ Tests

### Nouveaux tests Celery

```python
# Test avec Celery activ√©
def test_celery_heavy_report():
    with patch('CELERY_AVAILABLE', True):
        resp = client.post("/api/v1/reports/heavy?report_type=pdf")
        assert resp.status_code == 200

# Test fallback RQ
def test_celery_unavailable_fallback():
    with patch('CELERY_AVAILABLE', False):
        resp = client.post("/api/v1/reports/dummy")
        # Devrait utiliser RQ
```

## üîÑ Compatibilit√©

### R√©trocompatibilit√©

- **API existante**: Toutes les routes `/reports/dummy` fonctionnent
- **Tests existants**: Passent sans modification
- **Fallback RQ**: Activ√© si Celery indisponible
- **Jobs inline**: Support√©s pour les tests

### Migration progressive

1. **Phase 1**: D√©ploiement parall√®le (RQ + Celery)
2. **Phase 2**: Migration trafic vers Celery
3. **Phase 3**: Suppression code RQ (future)

## ‚ö†Ô∏è Consid√©rations

### D√©pendances

- **Celery 5.4.0**: Ajout√© aux requirements
- **Flower**: Optionnel pour monitoring
- **Redis**: Broker partag√© RQ/Celery

### Performance

- **Overhead**: L√©ger overhead Celery vs RQ
- **Scalabilit√©**: Meilleure avec workers sp√©cialis√©s
- **Monitoring**: Plus riche avec Flower + m√©triques

### S√©curit√©

- **S√©rialisation JSON**: Plus s√ªre que pickle
- **Validation t√¢ches**: Par queue et type
- **Isolation workers**: Par fonction m√©tier

## üéØ Prochaines √©tapes

1. **Tests de charge**: Valider performance sous charge
2. **Alertes**: Int√©grer alertes Prometheus/Grafana  
3. **Callbacks**: Webhooks post-g√©n√©ration
4. **Stockage**: Int√©gration S3 pour gros fichiers
5. **Nettoyage**: Suppression code RQ legacy
